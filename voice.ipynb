#cell:1
print("--- Starting Environment Setup ---")
!pip install librosa soundfile scikit-learn matplotlib Pillow
print("\n2. Ensuring NumPy compatibility (this will force a restart)...")
!pip install numpy==1.26.4 --force-reinstall
print("\n-------------------------------------------------------------")
print("Installation complete for now. YOU MUST RESTART THE RUNTIME!")
print("Look for the 'Restart runtime' button/prompt and click it.")
print("After restarting, run all cells again from the beginning.")
print("-------------------------------------------------------------\n")
exit() 
# cell:2
print("--- Re-Importing Libraries ---")

import numpy as np
import matplotlib.pyplot as plt
import time
import os

import librosa
import soundfile as sf
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler

from google.colab import files

print("Libraries re-imported. Verifying NumPy version...")
print(f"NumPy version currently loaded: {np.__version__}")

if np.__version__ == '1.26.4':
    print("NumPy version is correct (1.26.4). Good to go!")
else:
    print("WARNING: NumPy version might not be 1.26.4. If you face errors, manually restart runtime ('Runtime' -> 'Restart session') and try again.")

print("\nSetup verification complete. Proceed to next cell.")


# Cell 3: Data Preparation: Uploading Audio Samples
print("--- Data Preparation: Upload Your Audio Samples ---")
print("Please upload your .wav audio files now. (e.g., speaker1_enroll_01.wav, speaker2_test_01.wav)")

enrollment_dir = 'enrollment_samples'
test_dir = 'test_samples'
os.makedirs(enrollment_dir, exist_ok=True)
os.makedirs(test_dir, exist_ok=True)

uploaded_files = files.upload()

print("\nProcessing uploaded files...")

all_audio_files = []

for filename in uploaded_files.keys():
    parts = filename.split('_')
    speaker_name = parts[0]
    sample_type = parts[1]

    destination_path = ""
    if sample_type == 'enroll':
        destination_path = os.path.join(enrollment_dir, filename)
    elif sample_type == 'test':
        destination_path = os.path.join(test_dir, filename)
    else:
        print(f"Skipping unknown file type: {filename}. Please use 'enroll' or 'test' in filename.")
        continue

    with open(filename, 'wb') as f:
        f.write(uploaded_files[filename])
    os.rename(filename, destination_path)

    all_audio_files.append({'speaker': speaker_name, 'type': sample_type, 'path': destination_path})
    print(f"  Moved '{filename}' to '{destination_path}'")

print("\nAudio file organization complete.")
print(f"Total uploaded files: {len(all_audio_files)}")
print(f"Enrollment files: {len([f for f in all_audio_files if f['type'] == 'enroll'])}")
print(f"Test files: {len([f for f in all_audio_files if f['type'] == 'test'])}")



#cell:4
print("--- Feature Extraction (MFCCs) ---")

SAMPLING_RATE = 22050
N_MFCC = 13

import librosa
import numpy as np
import os

def extract_mfcc(audio_path, sr=SAMPLING_RATE, n_mfcc=N_MFCC):
    try:
        y, loaded_sr = librosa.load(audio_path, sr=sr)
        mfccs = librosa.feature.mfcc(y=y, sr=loaded_sr, n_mfcc=n_mfcc)
        averaged_mfccs = np.mean(mfccs.T, axis=0)
        return averaged_mfccs
    except Exception as e:
        print(f"Error processing {audio_path}: {e}")
        return None

X_features = []
y_labels = []

print("\nExtracting MFCCs from enrollment samples...")
enrollment_files_info = [f for f in all_audio_files if f['type'] == 'enroll']
for file_info in enrollment_files_info:
    mfcc_vector = extract_mfcc(file_info['path'])
    if mfcc_vector is not None:
        X_features.append(mfcc_vector)
        y_labels.append(file_info['speaker'])
        print(f"  Extracted MFCCs for {file_info['speaker']} from {os.path.basename(file_info['path'])}")

X_features = np.array(X_features)
y_labels = np.array(y_labels)

print("\nMFCC extraction complete.")
print(f"Shape of features (X): {X_features.shape}")
print(f"Shape of labels (y): {y_labels.shape}")

if X_features.shape[0] == 0:
    print("WARNING: No features extracted. Please ensure you uploaded valid audio files following the naming convention.")
else:
    print("Features ready for training!")
#cell:5
print("--- Model Training ---")

print(f"Number of feature samples: {len(X_features)}")
print(f"Speaker labels found: {y_labels}")
print(f"Unique speakers: {np.unique(y_labels)}")

if X_features.shape[0] < 2 or len(np.unique(y_labels)) < 2:
    print("ERROR: Not enough data or unique speakers to train a model.")
    print("Please upload at least 2 enrollment samples for at least 2 distinct speakers.")
else:
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_features)
    print(f"Features scaled. Shape: {X_scaled.shape}")

    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y_labels, test_size=0.2, random_state=42
    )
    print(f"Data split: Train samples={X_train.shape[0]}, Test samples={X_test.shape[0]}")

    model = SVC(kernel='linear', C=1.0, random_state=42, probability=True)

    print("\nTraining the model...")
    train_start_time = time.time()
    model.fit(X_train, y_train)
    train_end_time = time.time()
    print(f"Model training complete in {round(train_end_time - train_start_time, 2)} seconds.")

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nModel accuracy on internal test set: {accuracy * 100:.2f}%")
print("Classification Report:\n", classification_report(y_test, y_pred))

print("\nModel trained and ready for authentication!")

#cell:6
print("--- Authentication Logic ---")

if 'model' not in locals() or 'scaler' not in locals():
    print("ERROR: Model or scaler not trained/initialized. Please run Cell 5 first.")
else:
    test_files_info = [f for f in all_audio_files if f['type'] == 'test']

    if not test_files_info:
        print("No test files found. Please upload test samples in Cell 3.")
    else:
        print("\nPerforming authentication on test samples...")

        for i, test_file_info in enumerate(test_files_info):
            test_audio_path = test_file_info['path']
            true_speaker = test_file_info['speaker']

            print(f"\n--- Test Sample {i+1}: '{os.path.basename(test_audio_path)}' (True speaker: {true_speaker}) ---")

            test_mfcc = extract_mfcc(test_audio_path)

            if test_mfcc is not None:
                test_mfcc_reshaped = test_mfcc.reshape(1, -1)
                test_mfcc_scaled = scaler.transform(test_mfcc_reshaped)
                predicted_speaker = model.predict(test_mfcc_scaled)[0]
                probabilities = model.predict_proba(test_mfcc_scaled)[0]
                class_labels = model.classes_
                speaker_probabilities = dict(zip(class_labels, probabilities))

                print(f"Predicted Speaker: {predicted_speaker}")
                print(f"True Speaker: {true_speaker}")
                print("Probabilities per speaker:")
                for speaker, prob in speaker_probabilities.items():
                    print(f"  {speaker}: {prob*100:.2f}%")

                if predicted_speaker == true_speaker:
                    print("Status: AUTHENTICATED (Correctly identified)")
                else:
                    print("Status: FAILED AUTHENTICATION (Incorrectly identified)")
            else:
                print(f"  Skipping test sample due to MFCC extraction error: {os.path.basename(test_audio_path)}")



